---
title: 图卷积神经网络理论基础阅读
date: 2021-10-26 16:43:36
tags: Graph
category: 随手记
---
[原文地址](http://xtf615.com/2019/02/24/gcn/)

# 从传统卷积到图卷积
## 为什么不通用
在传统卷积中（比如图像，文本），都是非常标准的数据，能够很自然的运用矩阵等结构化方式进行表示（比如RGB图像就是一个三通道二维矩阵）。

但是图通常来说用矩阵进行表示是不太恰当的，对于很多的图来说，如果使用邻接矩阵、度矩阵等来进行表示的话，我们会发现这个矩阵过于稀疏而且对称。这无疑浪费了很多的资源。

因此对于规整的数据，我们可以一个卷积核（比如3*3）一卷到底，但是对于图这种不太规整的数据（每个点的邻接点数量不同等问题），我们没有办法一卷到底。

## 解决的一种方法
我们知道，傅里叶变换的有一个性质:
```
两个函数的 卷积 等于 每个函数分别进行傅里叶变换后的 乘积 再做逆傅里叶变换  
```

也就是，如果将数据转化到频域，我们可能就能很轻松的对 **图** 结构进行卷积操作，这样能够用现存的很多研究成果和方法在图结构数据中（类比self-attention等的跨领域使用）。

# 傅里叶变换
## 傅里叶变化是什么
原文中说的很好，这里直接拿过来。
> 从数学角度，傅立叶变换就是将**周期函数**转化为一组**正交基**下的坐标表示，这个坐标表示就是傅立叶变换的结果。换句话说，周期函数是这些正交基的**线性组合**(向量的叠加), 线性组合系数构成的向量就是傅立叶变换的结果。

> 从信号处理领域角度，傅里叶变换将一个周期函数从**时域**（时间与振幅的关系）转化为**频域**（频率与振幅的关系）。做个类比，正交基选择的是正弦函数，每个正弦函数有个频率参数值，而每个正弦函数的振幅参数就是该基下对应的坐标值。所有正弦函数的振幅构成的**向量**就是傅立叶变换的结果。

## 详细过程可视化
下图详细阐述了傅里叶变换把一个函数从时域转化成频域的过程  
![傅里叶变换动图](https://upload.wikimedia.org/wikipedia/commons/2/2b/Fourier_series_and_transform.gif)

## 具体怎么做
首先我们应该知道，对于任何<b id='1'>周期函数</b>,都可以使用傅里叶级数展开，把他们变成有限个或者无限个不同**频率**和**振幅**的正（余）弦函数的线性组合。
> 当然，对于非周期函数我们可以将它视为一个周期为∞的周期函数  


![傅里叶级数展开](https://bkimg.cdn.bcebos.com/formula/5f36ce6b84684c8206c4cbe52e9457a4.svg)（1）

式中P是周期，x是时间，A<sub>i</sub>是振幅。  

频率
```
w = 2πn/P,   n>=1
```

在展开后，如果我们固定时间x，把频率 w 作为变量，我们就可以得到一幅频域图。  

![掐死教程](http://xtf615.com/picture/machine-learning/fourier_series_transform.jpg)

注意：频域图像横坐标是离散的，由于n的变化，它一定是2π/P的整数倍。所有的纵坐标都是振幅。

## 傅里叶级数到傅里叶变换
从下图中我们可以看到周期与频域图像的关系，当周期越大时，频域图像就越“连续”。  
![周期与频域图像的关系](http://xtf615.com/picture/machine-learning/fourier_transform_jishu.png)  

因为周期与频域成反比（w = 2πn/P），周期增大时，w减小，n*w也减小，不同频率间隔也就越紧凑。  
因此，当周期为∞大时，整个频域图像曲线会连起来，这时候我们就需要把求和变成积分。
```
f(x) = ∑F(x)sin(wx) = ∫F(x)sin(wx)
```
> 这里为了方便，把<a href='#1'>公式1</a>简写了

当然，也可以用[欧拉公式](https://www.matongxue.com/madocs/8.html)来改写傅里叶变换，实现 **时域** 和 **复频域** 之间的转化  

![复频域到时域](https://wikimedia.org/api/rest_v1/media/math/render/svg/58ef40b0b675ac15702977463aa5bcb54cb0e55f)

同时，也可以求出复频域到时域的变换（通过欧拉公式的共轭形式抵消掉复部）  
![傅里叶逆变换](https://wikimedia.org/api/rest_v1/media/math/render/svg/790f6ea709f777928e0b7b0e9c9db82f09f4e8ea)

# graph傅里叶变换
## 怎么进行
1. 在Graph中，拉普拉斯算子为拉普拉斯矩阵
2. 对拉普拉斯矩阵进行特征分解，得到特征向量和特征值（这两者一一对应，类似之间存在了一个函数双射）
3. 我们可以把传统傅里叶变换中，正弦函数替换成拉普拉斯矩阵的特征向量（正弦函数与频率一一对应，特征向量与特征值一一对应）

这一的替换的根源意义在于，Graph拉普拉斯矩阵的特征向量作为一组基的话，这组基是Graph上Dirichlet Energy最小的基

通过这一系列类比、桥接，实现了图上的傅里叶变换。
## 拉普拉斯算子
非混合二阶偏导数的和，能够反映函数的平滑程度  

对图像（假定只有上下左右共4个自由度(1,0),(−1,0),(0,1),(0,−1)，也就是图中每一个点，被扰动都只能变到上、下、左、右其中一个位置）求拉普拉斯算子：
```
(Δf)x,y=∂f(x,y)/∂x2+∂f(x,y)/∂y2
       ≈f(x+1,y)+f(x−1,y)−2f(x,y)+f(x,y+1)+f(x,y−1)−2f(x,y)
       =f(x+1,y)+f(x−1,y)+f(x,y+1)+f(x,y−1)−4f(x,y)
       =[f(x+1,y)−f(x,y)]+[f(x−1,y)−f(x,y)]+[f(x,y+1)−f(x,y)]+[f(x,y−1)−f(x,y)]
```
我们可以看到 f(x+1,y)−f(x,y) 相当于是从点(x,y)变化到点(x+1,y)获得的增益；同理，f(x−1,y)−f(x,y) 也就可看出从点(x,y)变化到点(x+1,y)获得的增益。这样，**拉普拉斯算子约等于在所有自由度上进行微小变化后获得的增益**  

同理，推广到Graph上，每一个点的自由度为所有一阶邻接点的个数（该点的度）,同时，为了便于衡量每次变化的增益，这里直接使用了连接两点之间边的权重(假设为1)作为两点之间的增益。  

因此对某个点的拉普拉斯算子(所有自由度上变化增益)为：  

(Δf)<sub>i</sub> = Σ<sub>j∈邻接点</sub>w<sub>ij</sub>(V<sub>i</sub> - V<sub>j</sub>)  
   = Σ<sub>j∈邻接点</sub>w<sub>ij</sub>V<sub>i</sub> - Σ<sub>j∈邻接点</sub>w<sub>ij</sub>V<sub>j</sub>  
   = D<sub>i</sub>V<sub>i</sub> - W<sub>i</sub>V<sub>i</sub>  
   = (D<sub>i</sub>-W<sub>i</sub>)V<sub>i</sub>

其中，D<sub>i</sub>是i点的度，W<sub>i</sub>是i点的邻接矩阵，w<sub>ij</sub>是连接点i,j的边的权重（这里假定是1）  
上式可以看成Graph的拉普拉斯算子作用在Graph某一结点上的结果。

我们也称 L = D-W 为Graph的拉普拉斯矩阵，也就是Graph的拉普拉斯算子。
